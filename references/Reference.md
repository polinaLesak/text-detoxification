# References

This file contains same useful links, which I found in the process of completing task.

* [Text Detoxification using Large Pre-trained Neural Models](https://aclanthology.org/2021.emnlp-main.629.pdf)
* [Probing Toxic Content in Large Pre-Trained Language Models](https://aclanthology.org/2021.acl-long.329.pdf)
* [Pretrained models](https://huggingface.co/transformers/v3.3.1/pretrained_models.html)
* [BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
* [Pyplot tutorial](https://matplotlib.org/stable/tutorials/pyplot.html)